# -*- coding: utf-8 -*-
"""CSE422_glass_source_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ABgQuhwBb0TdvTO2PmZpBX1Fl1soiRVL
"""

"""import numpy & pandas"""

import numpy as np
import pandas as pd

""" 3. Load the dataset as dataframe using pandas """

df = pd.read_csv('/content/sample_data/glass source classification dataset.csv')
df

""" 4. Handle missing values if needed """
df.isnull().sum()

from sklearn.impute import SimpleImputer
impute = SimpleImputer(missing_values=np.nan, strategy='mean')
impute.fit(df[['Ca']])
df['Ca'] = impute.transform(df[['Ca']])
df.isnull().sum()

""" 5.Encode Categorical Features """

from sklearn.preprocessing import LabelEncoder
enc = LabelEncoder()
df['Ba'] = enc.fit_transform(df['Ba'])
df['Fe'] = enc.fit_transform(df['Fe'])
df['Type'] = enc.fit_transform(df['Type'])
df

""" 6. Scale all the values between 0-1 with proper scaling technique """

from sklearn.preprocessing import MinMaxScaler
scaler= MinMaxScaler()
scaler.fit(df)
MinMaxScaler()
df_scaled = scaler.transform(df)

print("per-feature minimum after scaling:\n {}".format(df_scaled.min(axis=0)))
print("per-feature maximum after scaling:\n {}".format(df_scaled.max(axis=0)))

""" 7. Split the dataset into features and labels."""

#Split the dataset into features"""
features = df[["RI","Na","Mg","Al","Si","K","Ca","Ba","Fe"]]
features

#Split the dataset into labels
lebels = df[["Type"]]
lebels